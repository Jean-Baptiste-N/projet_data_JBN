import streamlit as st
from langchain_openai import AzureChatOpenAI
from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits.sql.base import create_sql_agent
from langchain import hub
from google.cloud import bigquery
import pandas as pd
import os
from sqlalchemy.engine import create_engine
from sqlalchemy_bigquery import BigQueryDialect
import time
from streamlit_lottie import st_lottie

MAIN_COLOR = "#FF4B4B"

# Style CSS personnalis√©
st.markdown(""" 
    <style>
    .main-title {
        color: #003366;
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 2rem;
        text-align: center;
    }
    .section-title {
        color: #003366;
        font-size: 1.8rem;
        font-weight: bold;
        margin: 1.5rem 0;
    }
    .card {
        padding: 1rem;
        border-radius: 10px;
        background-color: #f8f9fa;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
    }
    .thinking-animation {
        display: flex;
        justify-content: center;
        align-items: center;
        margin: 10px 0;
    }
    </style>
    <script src="https://unpkg.com/@lottiefiles/lottie-player@2.0.8/dist/lottie-player.js"></script>
""", unsafe_allow_html=True)

# Titre de la page
st.markdown("<h1 class='main-title' style='margin-top: -50px;'>ü§ñ Analyste IA</h1>", unsafe_allow_html=True)

try:
    # Configuration Azure OpenAI
    AZURE_CONFIG = {
        "api_version": "2023-05-15",
        "azure_endpoint": st.secrets["azure"]["AZURE_ENDPOINT"],
        "azure_deployment": st.secrets["azure"]["AZURE_DEPLOYMENT_NAME"],
        "api_key": st.secrets["azure"]["AZURE_API_KEY"]
    }

    @st.cache_resource
    def init_database():
        """Initialise la connexion √† la base de donn√©es.""" 
        try:
            # Chargement des secrets
            gcp_service_account = st.secrets["gcp_service_account"]
            project_id = gcp_service_account["project_id"]
            
            # Cr√©er l'URL de connexion BigQuery
            connection_string = f"bigquery://{project_id}/dbt_medical_analysis_join_total_morbidite"
            
            # Cr√©er le moteur SQLAlchemy avec les credentials
            engine = create_engine(
                connection_string,
                credentials_info=gcp_service_account
            )
            
            # Cr√©er la connexion SQLDatabase pour LangChain
            db = SQLDatabase(engine)
            
            return db
            
        except Exception as e:
            st.error(f"Erreur de connexion √† la base de donn√©es : {str(e)}")
            return None

    @st.cache_resource
    def init_agent():
        """Initialise l'agent LangChain.""" 
        try:
            # Initialiser le mod√®le LLM
            llm = AzureChatOpenAI(
                azure_endpoint=AZURE_CONFIG["azure_endpoint"],
                azure_deployment=AZURE_CONFIG["azure_deployment"],
                openai_api_version=AZURE_CONFIG["api_version"],
                api_key=AZURE_CONFIG["api_key"],
                temperature=0
            )
            
            # Initialiser la base de donn√©es
            db = init_database()
            if not db:
                return None
                
            # Cr√©er la bo√Æte √† outils SQL
            toolkit = SQLDatabaseToolkit(db=db, llm=llm)
            
            # Cr√©er un prompt syst√®me personnalis√© pour le contexte m√©dical
            system_message = """
            Vous √™tes un assistant m√©dical sp√©cialis√© dans l'analyse des donn√©es hospitali√®res fran√ßaises.
            Votre r√¥le est d'aider √† comprendre et analyser les tendances en mati√®re d'hospitalisations, de pathologies et de services m√©dicaux.

            Pour chaque question, vous devez :
            1. Analyser soigneusement la demande de l'utilisateur
            2. Cr√©er une requ√™te SQL pr√©cise et adapt√©e pour BigQuery
            3. Interpr√©ter les r√©sultats de mani√®re professionnelle et accessible
            4. Proposer des analyses compl√©mentaires pertinentes
            5. Fournir des visualisations claires et appropri√©es pour aider l'utilisateur
            6. R√©ponds √† l'utilisateur en Fran√ßais uniquement

            R√®gles importantes :
            - Les tables principales sont :
              * `class_join_total_morbidite_sexe_population` (donn√©es principales)
              * `class_join_total_morbidite_capacite_kpi` (donn√©es de capacit√©)
            - Utilisez la syntaxe SQL BigQuery (par exemple DATE() pour les dates)
            - Limitez les r√©sultats √† 10 lignes sauf si sp√©cifi√© autrement
            - Pr√©sentez les r√©sultats de mani√®re claire avec des √©mojis appropri√©s
            - Gardez un ton professionnel car nous parlons de sant√©
            - Proposez des analyses compl√©mentaires pertinentes

            Structure des donn√©es principales :
            
            1. Identification et Localisation
            - niveau (STRING) : Niveau administratif (d√©partement, r√©gion)
            - cle_unique (STRING) : Identifiant unique par enregistrement
            - sexe (STRING) : Homme/Femme/Ensemble
            - year (DATE) : Format AAAA-MM-JJ
            - annee (INTEGER) : Ann√©e en format num√©rique
            - region (STRING) : Code ou nom de la r√©gion
            - code_region (INTEGER) : Code num√©rique de la r√©gion
            - nom_region (STRING) : Nom complet de la r√©gion

            2. Pathologie
            - pathologie (STRING) : Code descriptif de la pathologie
            - code_pathologie (INTEGER) : Code num√©rique de la pathologie
            - nom_pathologie (STRING) : Nom complet de la pathologie

            3. Hospitalisations
            - nbr_hospi (INTEGER) : Nombre total d'hospitalisations
            - hospi_prog_24h (FLOAT) : Hospitalisations programm√©es (24h)
            - hospi_autres_24h (FLOAT) : Autres hospitalisations (24h)
            - hospi_total_24h (FLOAT) : Total hospitalisations en 24h
            - hospi_[1-9]J (FLOAT) : Hospitalisations par dur√©e (1-9 jours)
            - hospi_10J_19J (FLOAT) : Hospitalisations de 10 √† 19 jours
            - hospi_20J_29J (FLOAT) : Hospitalisations de 20 √† 29 jours
            - hospi_30J (FLOAT) : Hospitalisations de 30 jours et plus
            - hospi_total_jj (FLOAT) : Total toutes dur√©es confondues
            - AVG_duree_hospi (FLOAT) : Dur√©e moyenne des hospitalisations

            4. Donn√©es D√©mographiques
            Les donn√©es d√©mographiques sont exprim√©es en proportions (FLOAT) pour chaque tranche d'√¢ge :
            - tranche_age_0_1 : Nourrissons (0 √† 1 an)
            - tranche_age_1_4 : Jeunes enfants (1 √† 4 ans)
            - tranche_age_5_14 : Enfants (5 √† 14 ans)
            - tranche_age_15_24 : Adolescents et jeunes adultes (15 √† 24 ans)
            - tranche_age_25_34 : Jeunes adultes (25 √† 34 ans)
            - tranche_age_35_44 : Adultes (35 √† 44 ans)
            - tranche_age_45_54 : Adultes matures (45 √† 54 ans)
            - tranche_age_55_64 : Seniors actifs (55 √† 64 ans)
            - tranche_age_65_74 : Jeunes retrait√©s (65 √† 74 ans)
            - tranche_age_75_84 : Personnes √¢g√©es (75 √† 84 ans)
            - tranche_age_85_et_plus : Personnes tr√®s √¢g√©es (85 ans et plus)

            Ces proportions permettent d'analyser :
            - La r√©partition des hospitalisations par √¢ge
            - Les tendances sp√©cifiques √† certaines tranches d'√¢ge
            - La comparaison entre diff√©rentes r√©gions ou services m√©dicaux
            - L'√©volution temporelle de la structure d'√¢ge des patients

            5. Indicateurs de Sant√©
            - tx_brut_tt_age_pour_mille (FLOAT) : Taux brut pour 1 000 habitants
            - tx_standard_tt_age_pour_mille (FLOAT) : Taux standardis√© pour 1 000 habitants
            - indice_comparatif_tt_age_percent (FLOAT) : Indice standardis√© en pourcentage

            6. Classification et Population
            - classification (STRING) : Service m√©dical :
              * M (M√©decine)
              * C (Chirurgie)
              * SSR (Soins de Suite et de R√©adaptation)
              * O (Obst√©trique)
              * ESND (√âtablissement de Soin Longue Dur√©e)
              * PSY (Psychoth√©rapie)

            - population (INTEGER) : Population totale par d√©partement

            Donn√©es de capacit√© (table class_join_total_morbidite_capacite_kpi) :
            
            1. Capacit√© d'Accueil
            - lit_hospi_complete (FLOAT) : Nombre de lits en hospitalisation compl√®te
            - place_hospi_partielle (FLOAT) : Nombre de places en hospitalisation partielle
            - passage_urgence (FLOAT) : Nombre de passages aux urgences

            2. Activit√© Hospitali√®re
            - sejour_hospi_complete (FLOAT) : Nombre de s√©jours en hospitalisation compl√®te
            - sejour_hospi_partielle (FLOAT) : Nombre de s√©jours en hospitalisation partielle
            - journee_hospi_complete (FLOAT) : Nombre de journ√©es d'hospitalisation compl√®te

            N'h√©sitez pas √† croiser les donn√©es entre les tables pour fournir des analyses pertinentes.
            """
            
            # Cr√©er l'agent SQL avec le prompt personnalis√©
            agent = create_sql_agent(
                llm=llm,
                toolkit=toolkit,
                verbose=True,
                agent_type="openai-tools",
                prefix=system_message
            )
            
            return agent
            
        except Exception as e:
            st.error(f"Erreur d'initialisation de l'agent : {str(e)}")
            return None

    def update_thinking_status(placeholder, step):
        """Met √† jour le statut de r√©flexion de l'agent.""" 
        thinking_states = {
            'start': "Initialisation de l'analyse",
            'understanding': "Compr√©hension de votre question",
            'processing': "Traitement des informations hospitali√®res",
            'querying': "Extraction des donn√©es pertinentes",
            'calculating': "Calcul des statistiques m√©dicales",
            'validating': "Validation des r√©sultats",
            'formatting': "Formulation de la r√©ponse"
        }
        
        lottie_url = "https://lottie.host/e4d1342b-0eb1-4182-9379-5859487f040d/b9l2rzI7Nh.json"
        
        with placeholder:
            st_lottie(lottie_url, height=300)

    def get_contextual_suggestions(user_input):

        templates = {
            "pathologie": ["Quelles pathologies sont les plus fr√©quentes ?", "√âvolution des hospitalisations par pathologie ?", "Comparaison des r√©gions sur les pathologies."],
            "region": ["Quelles r√©gions ont le plus d'hospitalisations ?", "Comparer les r√©gions sur le taux brut.", "Top r√©gions selon l'indice standardis√©."],
            "ann√©e": ["Tendances des hospitalisations pour l'ann√©e sp√©cifi√©e ?", "Comment le taux brut √©volue-t-il sur plusieurs ann√©es ?", "Focus sur une r√©gion pour une ann√©e sp√©cifique ?"]
        }
        
        # Analyse simple du contexte via mots-cl√©s
        context = []
        if any(word in user_input.lower() for word in ["pathologie", "maladie", "diagnostic"]):
            context.append("pathologie")
        if any(word in user_input.lower() for word in ["r√©gion", "d√©partement", "localisation"]):
            context.append("region")
        if any(word in user_input.lower() for word in ["ann√©e", "√©volution", "tendance"]):
            context.append("ann√©e")
        
        # Combine les suggestions pertinentes
        suggestions = [template for key in context for template in templates.get(key, [])]
        return suggestions if suggestions else ["Besoin d'aide pour poser une question ?"]

    def main():
        # Initialiser l'historique des messages
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # Cr√©er les containers
        chat_container = st.container()
        suggestions_container = st.container()
        input_container = st.container()

        # Afficher l'historique des messages dans le chat container
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

        # G√©rer l'entr√©e utilisateur
        with input_container:
            if prompt := st.chat_input("Posez votre question sur les donn√©es m√©dicales..."):
                # Ajouter la question √† l'historique
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # Afficher la question
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Afficher le message "en cours de r√©flexion"
                with st.chat_message("assistant"):
                    message_placeholder = st.empty()
                    
                    try:

                        update_thinking_status(message_placeholder, 'validating')
                        response = st.session_state.agent.invoke(prompt)


                        final_response = response.get('output', "Je n'ai pas pu g√©n√©rer une r√©ponse.")
                        message_placeholder.markdown(final_response)
                        
                        # Ajouter la r√©ponse √† l'historique
                        st.session_state.messages.append({"role": "assistant", "content": final_response})
                        st.rerun()
                    
                    except Exception as e:
                        message_placeholder.markdown(f"‚ùå D√©sol√©, une erreur s'est produite : {str(e)}")

        # Afficher les suggestions apr√®s chaque r√©ponse
        if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
            with suggestions_container:
                st.markdown("### üí¨ Discussion")
                suggestions = get_contextual_suggestions(st.session_state.messages[-2]["content"])  # Get suggestions based on last user message
                
                # Cr√©er des colonnes pour les suggestions
                num_suggestions = len(suggestions)
                if num_suggestions > 0:
                    cols = st.columns(min(3, num_suggestions))  # Maximum 3 colonnes
                    for idx, suggestion in enumerate(suggestions):
                        col_idx = idx % min(3, num_suggestions)
                        with cols[col_idx]:
                            if st.button(suggestion, key=f"sugg_{idx}"):
                                st.session_state.messages.append({"role": "user", "content": suggestion})
                                with st.chat_message("user"):
                                    st.markdown(suggestion)
                                 
                                with st.chat_message("assistant"):
                                    message_placeholder = st.empty()
                                    try:
                                        response = st.session_state.agent.invoke(prompt)

                                        final_response = response.get('output', "Je n'ai pas pu g√©n√©rer une r√©ponse.")
                                        message_placeholder.markdown(final_response)
                                        st.session_state.messages.append({"role": "assistant", "content": final_response})
                                        st.rerun()
                                    except Exception as e:
                                        message_placeholder.markdown(f"‚ùå D√©sol√©, une erreur s'est produite : {str(e)}")

        # Bouton pour nouvelle conversation
        if st.button("üîÑ Nouvelle conversation"):
            st.session_state.messages = []
            st.rerun()

    # Initialisation uniquement si tous les imports sont disponibles
    if 'agent' not in st.session_state:
        db = init_database()
        if db is not None:
            st.session_state.agent = init_agent()

    # Interface utilisateur
    main()

except ImportError as e:
    st.error(f"Certains packages requis ne sont pas install√©s : {str(e)}")
    st.info("Assurez-vous d'avoir install√© tous les packages n√©cessaires : langchain-openai, langchain-community, sqlalchemy-bigquery")
except Exception as e:
    st.error(f"Une erreur s'est produite : {str(e)}")

col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    st.image("pages/gooey.ai - ultra detailed 8k cg hospital medical room equipment.png", width=600)
    
st.markdown("---")
st.markdown("D√©velopp√© avec üí´| Le Wagon - Batch #1834 - Promotion 2024")
